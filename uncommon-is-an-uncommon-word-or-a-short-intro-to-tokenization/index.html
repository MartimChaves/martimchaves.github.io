<!doctype html><html lang=en-US><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://martimchaves.github.io/images/favicon.png><title>uncommon is an uncommon word - or a short intro to tokenization | low throughput thought stream</title>
<meta name=title content="uncommon is an uncommon word - or a short intro to tokenization"><meta name=description content="short intro to tokenization"><meta name=keywords content="LLM,language,"><meta property="og:url" content="https://martimchaves.github.io/uncommon-is-an-uncommon-word-or-a-short-intro-to-tokenization/"><meta property="og:site_name" content="low throughput thought stream"><meta property="og:title" content="uncommon is an uncommon word - or a short intro to tokenization"><meta property="og:description" content="short intro to tokenization"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-01-30T11:22:13+00:00"><meta property="article:modified_time" content="2025-01-30T11:22:13+00:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Language"><meta property="og:image" content="https://martimchaves.github.io/images/share.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://martimchaves.github.io/images/share.png"><meta name=twitter:title content="uncommon is an uncommon word - or a short intro to tokenization"><meta name=twitter:description content="short intro to tokenization"><meta itemprop=name content="uncommon is an uncommon word - or a short intro to tokenization"><meta itemprop=description content="short intro to tokenization"><meta itemprop=datePublished content="2025-01-30T11:22:13+00:00"><meta itemprop=dateModified content="2025-01-30T11:22:13+00:00"><meta itemprop=wordCount content="300"><meta itemprop=image content="https://martimchaves.github.io/images/share.png"><meta itemprop=keywords content="LLM,Language"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:800px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fff;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--code-background-color:#f2f2f2;--code-color:#222;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#333;--heading-color:#eee;--text-color:#ddd;--link-color:#8cc2dd;--visited-color:#8b6fcb;--code-background-color:#777;--code-color:#ddd;--blockquote-color:#ccc}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px}blockquote{border-left:1px solid #999;color:var(--code-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto!important}.highlight,.code{padding:1px 15px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style></head><body><header><a href=/ class=title><h1>low throughput thought stream</h1><h3>by martim chaves</h3></a><nav><a href=/>home</a>
<a href=/blog>blog</a></nav></header><main><h1>uncommon is an uncommon word - or a short intro to tokenization</h1><p><i><time datetime=2025-01-30>30 Jan, 2025</time></i></p><content><p>did you know that &ldquo;uncommon&rdquo; is an uncommon word? we can arrive at this conclusion from tokenizers! creating a tokenizer is the first step towards building a large language model (LLM). tokenizers create tokens that can, ideally, represent the smallest units of meaning in language. for example, the word &ldquo;influx&rdquo; can be broken down into two tokens, &ldquo;in&rdquo; and &ldquo;flux&rdquo;.</p><p>the &ldquo;in&rdquo; token carries plenty of meaning, being used in the formation of other words, such as &ldquo;incoming&rdquo; for things that are coming in, into us. and &ldquo;flux&rdquo; also encapsulates an idea, flow, movement. but tokens aren&rsquo;t always sub-representations of words. tokens can also be entire words, like &ldquo;hello&rdquo;. the principal idea is that tokens are the lego blocks of language, used to construct text with meaning.</p><p>so you may be wondering, what exactly are tokenizers? in essence they&rsquo;re big tables that assign an id to a token. and in the process of creating these tables we determine which groups of letters should actually be considered tokens. doing this involves looking at the frequency of words and how the words are built. this helps us determine which groups of letters are more frequent and more indicative of relevant tokens.</p><p>from this process, very common words are actually assigned their own tokens. curiously, &ldquo;uncommon&rdquo; does not get its own token, and so we conclude that &ldquo;uncommon&rdquo; is an uncommon word!</p><p>i mentioned that tokenizers aim to build a table with the smallest units of meaning in language, but they also have another important role - compression. by creating tokens we reduce the number of building blocks needed to represent language compared to assigning each word an id. see for example the words &ldquo;incoming&rdquo;, &ldquo;in&rdquo;, and &ldquo;coming&rdquo;. with just two tokens, &ldquo;in&rdquo; and &ldquo;coming&rdquo;, we are able to represent these three words.</p></content><p><a href=https://martimchaves.github.io/blog/llm/>#LLM</a>
<a href=https://martimchaves.github.io/blog/language/>#Language</a></p></main><footer>made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>